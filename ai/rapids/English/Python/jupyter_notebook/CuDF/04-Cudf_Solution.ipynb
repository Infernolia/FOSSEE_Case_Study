{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&ensp;\n",
    "[Home Page](../START_HERE.ipynb)\n",
    "\n",
    "[Previous Notebook](03-Cudf_Exercise.ipynb)\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "[1](01-Intro_to_cuDF.ipynb)\n",
    "[2](02-Intro_to_cuDF_UDFs.ipynb)\n",
    "[3](03-Cudf_Exercise.ipynb)\n",
    "[4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying CuDF: The Solution\n",
    "\n",
    "Welcome to fourth cuDF tutorial notebook! This is a practical example that utilizes cuDF and cuPy, geared primarily for new users. The purpose of this tutorial is to introduce new users to a data science processing pipeline using RAPIDS on real life datasets. We will be working on a data science problem: US Accidents Prediction. This is a countrywide car accident dataset, which covers 49 states of the USA. The accident data are collected from February 2016 to June 2020, using two APIs that provide streaming traffic incident (or event) data. These APIs broadcast traffic data captured by a variety of entities, such as the US and state departments of transportation, law enforcement agencies, traffic cameras, and traffic sensors within the road-networks. Currently, there are about 3.5 million accident records in this dataset. \n",
    "\n",
    "\n",
    "## What should I do?\n",
    "\n",
    "Given below is a complete data science preprocessing pipeline for the dataset using Pandas and Numpy libraries. Using the methods and techniques from the previous notebooks, you have to convert this pipeline to a a RAPIDS implementation, using CuDF and CuPy. Don't forget to time your code cells and compare the performance with this original code, to understand why we are using RAPIDS. If you get stuck in the middle, feel free to refer to this sample solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the list of exercises in the lab where you need to modify code:\n",
    "- <a href='#ex1'>Exercise 1</a><br> Loading the dataset from a csv file and store in a CuDF dataframe.\n",
    "- <a href='#ex2'>Exercise 2</a><br> Creating kernel functions to run the given function optimally on a GPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is downloading the dataset and putting it in the data directory, for using in this tutorial.\n",
    "Download the dataset here, and place it in (host/data) folder. Now we will import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cudf\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import math\n",
    "np.random.seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ex1'></a>\n",
    "\n",
    "First we need to load the dataset from the csv into CuDF dataframes, for the preprocessing steps. If you need help, refer to the Getting Data In and Out module from this [notebook](01-Intro_to_cuDF.ipynb/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.25 s, sys: 619 ms, total: 1.87 s\n",
      "Wall time: 1.87 s\n",
      "                ID    Source    TMC  Severity           Start_Time  \\\n",
      "0              A-1  MapQuest  201.0         3  2016-02-08 05:46:00   \n",
      "1              A-2  MapQuest  201.0         2  2016-02-08 06:07:59   \n",
      "2              A-3  MapQuest  201.0         2  2016-02-08 06:49:27   \n",
      "3              A-4  MapQuest  201.0         3  2016-02-08 07:23:34   \n",
      "4              A-5  MapQuest  201.0         2  2016-02-08 07:39:07   \n",
      "...            ...       ...    ...       ...                  ...   \n",
      "3513612  A-3513776      Bing   <NA>         2  2019-08-23 18:03:25   \n",
      "3513613  A-3513777      Bing   <NA>         2  2019-08-23 19:11:30   \n",
      "3513614  A-3513778      Bing   <NA>         2  2019-08-23 19:00:21   \n",
      "3513615  A-3513779      Bing   <NA>         2  2019-08-23 19:00:21   \n",
      "3513616  A-3513780      Bing   <NA>         2  2019-08-23 18:52:06   \n",
      "\n",
      "                    End_Time  Start_Lat   Start_Lng   End_Lat     End_Lng  \\\n",
      "0        2016-02-08 11:00:00  39.865147  -84.058723      <NA>        <NA>   \n",
      "1        2016-02-08 06:37:59  39.928059  -82.831184      <NA>        <NA>   \n",
      "2        2016-02-08 07:19:27  39.063148  -84.032608      <NA>        <NA>   \n",
      "3        2016-02-08 07:53:34  39.747753  -84.205582      <NA>        <NA>   \n",
      "4        2016-02-08 08:09:07  39.627781  -84.188354      <NA>        <NA>   \n",
      "...                      ...        ...         ...       ...         ...   \n",
      "3513612  2019-08-23 18:32:01  34.002480 -117.379360  33.99888  -117.37094   \n",
      "3513613  2019-08-23 19:38:23  32.766960 -117.148060  32.76555  -117.15363   \n",
      "3513614  2019-08-23 19:28:49  33.775450 -117.847790   33.7774  -117.85727   \n",
      "3513615  2019-08-23 19:29:42  33.992460 -118.403020  33.98311  -118.39565   \n",
      "3513616  2019-08-23 19:21:31  34.133930 -117.230920  34.13736  -117.23934   \n",
      "\n",
      "         ...  Roundabout  Station   Stop  Traffic_Calming  Traffic_Signal  \\\n",
      "0        ...       False    False  False            False           False   \n",
      "1        ...       False    False  False            False           False   \n",
      "2        ...       False    False  False            False            True   \n",
      "3        ...       False    False  False            False           False   \n",
      "4        ...       False    False  False            False            True   \n",
      "...      ...         ...      ...    ...              ...             ...   \n",
      "3513612  ...       False    False  False            False           False   \n",
      "3513613  ...       False    False  False            False           False   \n",
      "3513614  ...       False    False  False            False           False   \n",
      "3513615  ...       False    False  False            False           False   \n",
      "3513616  ...       False    False  False            False           False   \n",
      "\n",
      "         Turning_Loop  Sunrise_Sunset Civil_Twilight Nautical_Twilight  \\\n",
      "0               False           Night          Night             Night   \n",
      "1               False           Night          Night             Night   \n",
      "2               False           Night          Night               Day   \n",
      "3               False           Night            Day               Day   \n",
      "4               False             Day            Day               Day   \n",
      "...               ...             ...            ...               ...   \n",
      "3513612         False             Day            Day               Day   \n",
      "3513613         False             Day            Day               Day   \n",
      "3513614         False             Day            Day               Day   \n",
      "3513615         False             Day            Day               Day   \n",
      "3513616         False             Day            Day               Day   \n",
      "\n",
      "        Astronomical_Twilight  \n",
      "0                       Night  \n",
      "1                         Day  \n",
      "2                         Day  \n",
      "3                         Day  \n",
      "4                         Day  \n",
      "...                       ...  \n",
      "3513612                   Day  \n",
      "3513613                   Day  \n",
      "3513614                   Day  \n",
      "3513615                   Day  \n",
      "3513616                   Day  \n",
      "\n",
      "[3513617 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "%time df = cudf.read_csv('../../data/data.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First we will analyse the data and observe patterns that can help us process the data better for feeding to the machine learning algorithms in the future. By using the describe, we will generate the descriptive statistics for all the columns. Descriptive statistics include those that summarize the central tendency, dispersion and shape of a dataset’s distribution, excluding NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TMC</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>Number</th>\n",
       "      <th>Temperature(F)</th>\n",
       "      <th>Wind_Chill(F)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Pressure(in)</th>\n",
       "      <th>Visibility(mi)</th>\n",
       "      <th>Wind_Speed(mph)</th>\n",
       "      <th>Precipitation(in)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.478818e+06</td>\n",
       "      <td>3.513617e+06</td>\n",
       "      <td>3.513617e+06</td>\n",
       "      <td>3.513617e+06</td>\n",
       "      <td>1.034799e+06</td>\n",
       "      <td>1.034799e+06</td>\n",
       "      <td>3.513617e+06</td>\n",
       "      <td>1.250753e+06</td>\n",
       "      <td>3.447885e+06</td>\n",
       "      <td>1.645368e+06</td>\n",
       "      <td>3.443930e+06</td>\n",
       "      <td>3.457735e+06</td>\n",
       "      <td>3.437761e+06</td>\n",
       "      <td>3.059008e+06</td>\n",
       "      <td>1.487743e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.080226e+02</td>\n",
       "      <td>2.339929e+00</td>\n",
       "      <td>3.654194e+01</td>\n",
       "      <td>-9.579151e+01</td>\n",
       "      <td>3.755758e+01</td>\n",
       "      <td>-1.004560e+02</td>\n",
       "      <td>2.816170e-01</td>\n",
       "      <td>5.975383e+03</td>\n",
       "      <td>6.193512e+01</td>\n",
       "      <td>5.355730e+01</td>\n",
       "      <td>6.511427e+01</td>\n",
       "      <td>2.974463e+01</td>\n",
       "      <td>9.122644e+00</td>\n",
       "      <td>8.219025e+00</td>\n",
       "      <td>1.598300e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.076627e+01</td>\n",
       "      <td>5.521930e-01</td>\n",
       "      <td>4.883520e+00</td>\n",
       "      <td>1.736877e+01</td>\n",
       "      <td>4.861215e+00</td>\n",
       "      <td>1.852879e+01</td>\n",
       "      <td>1.550134e+00</td>\n",
       "      <td>1.496624e+04</td>\n",
       "      <td>1.862106e+01</td>\n",
       "      <td>2.377334e+01</td>\n",
       "      <td>2.275558e+01</td>\n",
       "      <td>8.319760e-01</td>\n",
       "      <td>2.885879e+00</td>\n",
       "      <td>5.262847e+00</td>\n",
       "      <td>1.928260e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.455527e+01</td>\n",
       "      <td>-1.246238e+02</td>\n",
       "      <td>2.457011e+01</td>\n",
       "      <td>-1.244978e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-8.900000e+01</td>\n",
       "      <td>-8.900000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.010000e+02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.363784e+01</td>\n",
       "      <td>-1.174418e+02</td>\n",
       "      <td>3.399477e+01</td>\n",
       "      <td>-1.183440e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.640000e+02</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>3.570000e+01</td>\n",
       "      <td>4.800000e+01</td>\n",
       "      <td>2.973000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.010000e+02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.591687e+01</td>\n",
       "      <td>-9.102601e+01</td>\n",
       "      <td>3.779736e+01</td>\n",
       "      <td>-9.703438e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.798000e+03</td>\n",
       "      <td>6.400000e+01</td>\n",
       "      <td>5.700000e+01</td>\n",
       "      <td>6.700000e+01</td>\n",
       "      <td>2.995000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.010000e+02</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.032217e+01</td>\n",
       "      <td>-8.093299e+01</td>\n",
       "      <td>4.105139e+01</td>\n",
       "      <td>-8.210168e+01</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>7.098000e+03</td>\n",
       "      <td>7.590000e+01</td>\n",
       "      <td>7.200000e+01</td>\n",
       "      <td>8.400000e+01</td>\n",
       "      <td>3.009000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.150000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.060000e+02</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.900220e+01</td>\n",
       "      <td>-6.711317e+01</td>\n",
       "      <td>4.907500e+01</td>\n",
       "      <td>-6.710924e+01</td>\n",
       "      <td>3.336300e+02</td>\n",
       "      <td>9.999997e+06</td>\n",
       "      <td>1.706000e+02</td>\n",
       "      <td>1.150000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>5.774000e+01</td>\n",
       "      <td>1.400000e+02</td>\n",
       "      <td>9.840000e+02</td>\n",
       "      <td>2.500000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TMC      Severity     Start_Lat     Start_Lng       End_Lat  \\\n",
       "count  2.478818e+06  3.513617e+06  3.513617e+06  3.513617e+06  1.034799e+06   \n",
       "mean   2.080226e+02  2.339929e+00  3.654194e+01 -9.579151e+01  3.755758e+01   \n",
       "std    2.076627e+01  5.521930e-01  4.883520e+00  1.736877e+01  4.861215e+00   \n",
       "min    2.000000e+02  1.000000e+00  2.455527e+01 -1.246238e+02  2.457011e+01   \n",
       "25%    2.010000e+02  2.000000e+00  3.363784e+01 -1.174418e+02  3.399477e+01   \n",
       "50%    2.010000e+02  2.000000e+00  3.591687e+01 -9.102601e+01  3.779736e+01   \n",
       "75%    2.010000e+02  3.000000e+00  4.032217e+01 -8.093299e+01  4.105139e+01   \n",
       "max    4.060000e+02  4.000000e+00  4.900220e+01 -6.711317e+01  4.907500e+01   \n",
       "\n",
       "            End_Lng  Distance(mi)        Number  Temperature(F)  \\\n",
       "count  1.034799e+06  3.513617e+06  1.250753e+06    3.447885e+06   \n",
       "mean  -1.004560e+02  2.816170e-01  5.975383e+03    6.193512e+01   \n",
       "std    1.852879e+01  1.550134e+00  1.496624e+04    1.862106e+01   \n",
       "min   -1.244978e+02  0.000000e+00  0.000000e+00   -8.900000e+01   \n",
       "25%   -1.183440e+02  0.000000e+00  8.640000e+02    5.000000e+01   \n",
       "50%   -9.703438e+01  0.000000e+00  2.798000e+03    6.400000e+01   \n",
       "75%   -8.210168e+01  1.000000e-02  7.098000e+03    7.590000e+01   \n",
       "max   -6.710924e+01  3.336300e+02  9.999997e+06    1.706000e+02   \n",
       "\n",
       "       Wind_Chill(F)   Humidity(%)  Pressure(in)  Visibility(mi)  \\\n",
       "count   1.645368e+06  3.443930e+06  3.457735e+06    3.437761e+06   \n",
       "mean    5.355730e+01  6.511427e+01  2.974463e+01    9.122644e+00   \n",
       "std     2.377334e+01  2.275558e+01  8.319760e-01    2.885879e+00   \n",
       "min    -8.900000e+01  1.000000e+00  0.000000e+00    0.000000e+00   \n",
       "25%     3.570000e+01  4.800000e+01  2.973000e+01    1.000000e+01   \n",
       "50%     5.700000e+01  6.700000e+01  2.995000e+01    1.000000e+01   \n",
       "75%     7.200000e+01  8.400000e+01  3.009000e+01    1.000000e+01   \n",
       "max     1.150000e+02  1.000000e+02  5.774000e+01    1.400000e+02   \n",
       "\n",
       "       Wind_Speed(mph)  Precipitation(in)  \n",
       "count     3.059008e+06       1.487743e+06  \n",
       "mean      8.219025e+00       1.598300e-02  \n",
       "std       5.262847e+00       1.928260e-01  \n",
       "min       0.000000e+00       0.000000e+00  \n",
       "25%       5.000000e+00       0.000000e+00  \n",
       "50%       7.000000e+00       0.000000e+00  \n",
       "75%       1.150000e+01       0.000000e+00  \n",
       "max       9.840000e+02       2.500000e+01  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check the size of the dataset that is to be processed using the len function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3513617"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that the dataset has 3513616 rows and takes quite a lot of time to read from the file. As we go ahead with the preprocessing, computations will require more time to execute, and that's where the RAPIDS comes to the rescue!\n",
    "\n",
    "Now we use the info function to check the datatype of all the columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'>\n",
      "RangeIndex: 3513617 entries, 0 to 3513616\n",
      "Data columns (total 49 columns):\n",
      " #   Column                 Dtype\n",
      "---  ------                 -----\n",
      " 0   ID                     object\n",
      " 1   Source                 object\n",
      " 2   TMC                    float64\n",
      " 3   Severity               int64\n",
      " 4   Start_Time             object\n",
      " 5   End_Time               object\n",
      " 6   Start_Lat              float64\n",
      " 7   Start_Lng              float64\n",
      " 8   End_Lat                float64\n",
      " 9   End_Lng                float64\n",
      " 10  Distance(mi)           float64\n",
      " 11  Description            object\n",
      " 12  Number                 float64\n",
      " 13  Street                 object\n",
      " 14  Side                   object\n",
      " 15  City                   object\n",
      " 16  County                 object\n",
      " 17  State                  object\n",
      " 18  Zipcode                object\n",
      " 19  Country                object\n",
      " 20  Timezone               object\n",
      " 21  Airport_Code           object\n",
      " 22  Weather_Timestamp      object\n",
      " 23  Temperature(F)         float64\n",
      " 24  Wind_Chill(F)          float64\n",
      " 25  Humidity(%)            float64\n",
      " 26  Pressure(in)           float64\n",
      " 27  Visibility(mi)         float64\n",
      " 28  Wind_Direction         object\n",
      " 29  Wind_Speed(mph)        float64\n",
      " 30  Precipitation(in)      float64\n",
      " 31  Weather_Condition      object\n",
      " 32  Amenity                bool\n",
      " 33  Bump                   bool\n",
      " 34  Crossing               bool\n",
      " 35  Give_Way               bool\n",
      " 36  Junction               bool\n",
      " 37  No_Exit                bool\n",
      " 38  Railway                bool\n",
      " 39  Roundabout             bool\n",
      " 40  Station                bool\n",
      " 41  Stop                   bool\n",
      " 42  Traffic_Calming        bool\n",
      " 43  Traffic_Signal         bool\n",
      " 44  Turning_Loop           bool\n",
      " 45  Sunrise_Sunset         object\n",
      " 46  Civil_Twilight         object\n",
      " 47  Nautical_Twilight      object\n",
      " 48  Astronomical_Twilight  object\n",
      "dtypes: bool(13), float64(14), int64(1), object(21)\n",
      "memory usage: 1.4+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also check the number of missing values in the dataset, so that we can drop or fill in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                             0\n",
       "Source                         0\n",
       "TMC                      1034799\n",
       "Severity                       0\n",
       "Start_Time                     0\n",
       "End_Time                       0\n",
       "Start_Lat                      0\n",
       "Start_Lng                      0\n",
       "End_Lat                  2478818\n",
       "End_Lng                  2478818\n",
       "Distance(mi)                   0\n",
       "Description                    1\n",
       "Number                   2262864\n",
       "Street                         0\n",
       "Side                           0\n",
       "City                         112\n",
       "County                         0\n",
       "State                          0\n",
       "Zipcode                     1069\n",
       "Country                        0\n",
       "Timezone                    3880\n",
       "Airport_Code                6758\n",
       "Weather_Timestamp          43323\n",
       "Temperature(F)             65732\n",
       "Wind_Chill(F)            1868249\n",
       "Humidity(%)                69687\n",
       "Pressure(in)               55882\n",
       "Visibility(mi)             75856\n",
       "Wind_Direction             58874\n",
       "Wind_Speed(mph)           454609\n",
       "Precipitation(in)        2025874\n",
       "Weather_Condition          76138\n",
       "Amenity                        0\n",
       "Bump                           0\n",
       "Crossing                       0\n",
       "Give_Way                       0\n",
       "Junction                       0\n",
       "No_Exit                        0\n",
       "Railway                        0\n",
       "Roundabout                     0\n",
       "Station                        0\n",
       "Stop                           0\n",
       "Traffic_Calming                0\n",
       "Traffic_Signal                 0\n",
       "Turning_Loop                   0\n",
       "Sunrise_Sunset               115\n",
       "Civil_Twilight               115\n",
       "Nautical_Twilight            115\n",
       "Astronomical_Twilight        115\n",
       "dtype: uint64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many columns with null values, and we will fill them with random values or the mean from the column. We will drop some text columns, as we are not doing any natural language processing right now, but feel free to explore them on your own. We will also drop the columns with too many Nans as filling them will throw our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['ID','Start_Time','End_Time','Street','Side','Description','Number','City','Country','Zipcode','Timezone','Airport_Code','Weather_Timestamp','Wind_Chill(F)','Wind_Direction','Wind_Speed(mph)','Precipitation(in)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are filling the TMC with mean.\n",
    "df['TMC'] = df['TMC'].fillna(df['TMC'].mean())\n",
    "df['End_Lat'] = df['End_Lat'].fillna(df['End_Lat'].mean())\n",
    "df['End_Lng'] = df['End_Lng'].fillna(df['End_Lng'].mean())\n",
    "df['Temperature(F)'] = df['Temperature(F)'].fillna(df['Temperature(F)'].mean())\n",
    "df['Humidity(%)'] = df['Humidity(%)'].fillna(df['Humidity(%)'].mean())\n",
    "df['Pressure(in)'] = df['Pressure(in)'].fillna(df['Pressure(in)'].mean())\n",
    "df['Visibility(mi)'] = df['Visibility(mi)'].fillna(df['Visibility(mi)'].mean())\n",
    "df['Humidity(%)'] = df['Humidity(%)'].fillna(df['Humidity(%)'].mean())\n",
    "df['Pressure(in)'] = df['Pressure(in)'].fillna(df['Pressure(in)'].mean())\n",
    "df['Visibility(mi)'] = df['Visibility(mi)'].fillna(df['Visibility(mi)'].mean())\n",
    "\n",
    "\n",
    "df['Weather_Condition'] = df['Weather_Condition'].fillna('Fair')\n",
    "df['Sunrise_Sunset'] = df['Sunrise_Sunset'].fillna('Day')\n",
    "df['Civil_Twilight'] = df['Civil_Twilight'].fillna('Day')\n",
    "df['Nautical_Twilight'] = df['Nautical_Twilight'].fillna('Day')\n",
    "df['Astronomical_Twilight'] = df['Astronomical_Twilight'].fillna('Day')\n",
    "df['Weather_Condition'] = df['Weather_Condition'].fillna('Fair')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all the columns contain no Nan values and we can go ahead with the preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ex2'></a>\n",
    "       \n",
    "As you have observed in the dataset we have the start and end coordinates,so  let us apply Haversine distance formula to get the accident coverage distance. Take note of how these functions use the row-wise operations, something that we have learnt before. If you need help while creating the user defined functions refer to this [notebook](02-Intro_to_cuDF_UDFs.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import cos, sin, asin, sqrt, pi, atan2\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance_kernel(Start_Lat, Start_Lng, End_Lat, End_Lng, out):\n",
    " \n",
    "    for i, (x_1, y_1, x_2, y_2) in enumerate(zip(Start_Lat, Start_Lng, End_Lat, End_Lng)):\n",
    " \n",
    "\n",
    "        x_1 = pi/180 * x_1\n",
    "        y_1 = pi/180 * y_1\n",
    "        x_2 = pi/180 * x_2\n",
    "        y_2 = pi/180 * y_2\n",
    "        \n",
    "        dlon = y_2 - y_1\n",
    "        dlat = x_2 - x_1\n",
    "        a = sin(dlat/2)**2 + cos(x_1) * cos(x_2) * sin(dlon/2)**2\n",
    "        \n",
    "        c = 2 * asin(sqrt(a)) \n",
    "        r = 6371 # Radius of earth in kilometers\n",
    "        \n",
    "        out[i] = c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 602 ms, sys: 370 ms, total: 972 ms\n",
      "Wall time: 993 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = df.apply_rows(haversine_distance_kernel,\n",
    "                   incols=['Start_Lat', 'Start_Lng', 'End_Lat', 'End_Lng'],\n",
    "                   outcols=dict(out=np.float64),\n",
    "                   kwargs=dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! The code segment that previously took  7 minutes to compute, now gets executed in less than a second! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance_kernel(Start_Lat, Start_Lng, End_Lat, End_Lng, out):\n",
    " \n",
    "    for i, (x_1, y_1, x_2, y_2) in enumerate(zip(Start_Lat, Start_Lng, End_Lat, End_Lng)):\n",
    " \n",
    "\n",
    "        x_1 = pi/180 * x_1\n",
    "        y_1 = pi/180 * y_1\n",
    "        x_2 = pi/180 * x_2\n",
    "        y_2 = pi/180 * y_2\n",
    "        \n",
    "        dlon = y_2 - y_1\n",
    "        dlat = x_2 - x_1\n",
    "        a = sin(dlat/2)**2 + cos(x_1) * cos(x_2) * sin(dlon/2)**2\n",
    "        \n",
    "        c = 2 * asin(sqrt(a)) \n",
    "        r = 6371 # Radius of earth in kilometers\n",
    "        \n",
    "        out[i] = c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 496 ms, sys: 446 ms, total: 942 ms\n",
      "Wall time: 958 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "outdf = df.apply_chunks(haversine_distance_kernel,\n",
    "                        incols=['Start_Lat', 'Start_Lng', 'End_Lat', 'End_Lng'],\n",
    "                        outcols=dict(out=np.float64),\n",
    "                        kwargs=dict(),\n",
    "                        chunks=8,\n",
    "                        tpb=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel also took less than a second. The difference is merely the control we have over the execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe in a csv for future use, and make sure you refer to our sample solution and compared your code's performance with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>TMC</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>...</th>\n",
       "      <th>WC_Thunderstorm</th>\n",
       "      <th>WC_Thunderstorms and Rain</th>\n",
       "      <th>WC_Thunderstorms and Snow</th>\n",
       "      <th>WC_Tornado</th>\n",
       "      <th>WC_Volcanic Ash</th>\n",
       "      <th>WC_Widespread Dust</th>\n",
       "      <th>WC_Widespread Dust / Windy</th>\n",
       "      <th>WC_Wintry Mix</th>\n",
       "      <th>WC_Wintry Mix / Windy</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MapQuest</td>\n",
       "      <td>201.0</td>\n",
       "      <td>3</td>\n",
       "      <td>39.865147</td>\n",
       "      <td>-84.058723</td>\n",
       "      <td>37.557578</td>\n",
       "      <td>-100.455981</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.9</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1443.524390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MapQuest</td>\n",
       "      <td>201.0</td>\n",
       "      <td>2</td>\n",
       "      <td>39.928059</td>\n",
       "      <td>-82.831184</td>\n",
       "      <td>37.557578</td>\n",
       "      <td>-100.455981</td>\n",
       "      <td>0.01</td>\n",
       "      <td>37.9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1548.467903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MapQuest</td>\n",
       "      <td>201.0</td>\n",
       "      <td>2</td>\n",
       "      <td>39.063148</td>\n",
       "      <td>-84.032608</td>\n",
       "      <td>37.557578</td>\n",
       "      <td>-100.455981</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1440.697621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MapQuest</td>\n",
       "      <td>201.0</td>\n",
       "      <td>3</td>\n",
       "      <td>39.747753</td>\n",
       "      <td>-84.205582</td>\n",
       "      <td>37.557578</td>\n",
       "      <td>-100.455981</td>\n",
       "      <td>0.01</td>\n",
       "      <td>35.1</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1429.927497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MapQuest</td>\n",
       "      <td>201.0</td>\n",
       "      <td>2</td>\n",
       "      <td>39.627781</td>\n",
       "      <td>-84.188354</td>\n",
       "      <td>37.557578</td>\n",
       "      <td>-100.455981</td>\n",
       "      <td>0.01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1430.383177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1930 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Source    TMC  Severity  Start_Lat  Start_Lng    End_Lat     End_Lng  \\\n",
       "0  MapQuest  201.0         3  39.865147 -84.058723  37.557578 -100.455981   \n",
       "1  MapQuest  201.0         2  39.928059 -82.831184  37.557578 -100.455981   \n",
       "2  MapQuest  201.0         2  39.063148 -84.032608  37.557578 -100.455981   \n",
       "3  MapQuest  201.0         3  39.747753 -84.205582  37.557578 -100.455981   \n",
       "4  MapQuest  201.0         2  39.627781 -84.188354  37.557578 -100.455981   \n",
       "\n",
       "   Distance(mi)  Temperature(F)  Humidity(%)  ...  WC_Thunderstorm  \\\n",
       "0          0.01            36.9         91.0  ...                0   \n",
       "1          0.01            37.9        100.0  ...                0   \n",
       "2          0.01            36.0        100.0  ...                0   \n",
       "3          0.01            35.1         96.0  ...                0   \n",
       "4          0.01            36.0         89.0  ...                0   \n",
       "\n",
       "   WC_Thunderstorms and Rain  WC_Thunderstorms and Snow  WC_Tornado  \\\n",
       "0                          0                          0           0   \n",
       "1                          0                          0           0   \n",
       "2                          0                          0           0   \n",
       "3                          0                          0           0   \n",
       "4                          0                          0           0   \n",
       "\n",
       "   WC_Volcanic Ash  WC_Widespread Dust  WC_Widespread Dust / Windy  \\\n",
       "0                0                   0                           0   \n",
       "1                0                   0                           0   \n",
       "2                0                   0                           0   \n",
       "3                0                   0                           0   \n",
       "4                0                   0                           0   \n",
       "\n",
       "   WC_Wintry Mix  WC_Wintry Mix / Windy          out  \n",
       "0              0                      0  1443.524390  \n",
       "1              0                      0  1548.467903  \n",
       "2              0                      0  1440.697621  \n",
       "3              0                      0  1429.927497  \n",
       "4              0                      0  1430.383177  \n",
       "\n",
       "[5 rows x 1930 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data_proc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "Thus we have successfully used CuDF and CuPy to process the accidents dataset, and converted the data to a form more suitable to apply machine learning algorithms. In the extra labs for future labs in CuML we will be using this processed dataset. You must have observed the parallels between the RAPIDS pipeline and traditional pipeline while writing your code. Try to experiment with the processing and making your code as efficient as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, and Rajiv Ramnath. “A Countrywide Traffic Accident Dataset.”, 2019.\n",
    "\n",
    "- Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, Radu Teodorescu, and Rajiv Ramnath. \"Accident Risk Prediction based on Heterogeneous Sparse Data: New Dataset and Insights.\" In proceedings of the 27th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM, 2019.\n",
    "\n",
    "- If you need to refer to the dataset, you can download it [here](https://www.kaggle.com/sobhanmoosavi/us-accidents)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a></center><br />\n",
    "\n",
    "- This dataset is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Licensing\n",
    "  \n",
    "This material is released by NVIDIA Corporation under the Creative Commons Attribution 4.0 International (CC BY 4.0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Previous Notebook](03-Cudf_Exercise.ipynb)\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "[1](01-Intro_to_cuDF.ipynb)\n",
    "[2](02-Intro_to_cuDF_UDFs.ipynb)\n",
    "[3](03-Cudf_Exercise.ipynb)\n",
    "[4]\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "\n",
    "\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;\n",
    "&emsp;&emsp;&ensp;\n",
    "[Home Page](../START_HERE.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
